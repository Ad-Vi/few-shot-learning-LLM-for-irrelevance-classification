{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-07T11:46:26.211683Z","iopub.status.busy":"2023-12-07T11:46:26.211110Z","iopub.status.idle":"2023-12-07T11:46:31.870845Z","shell.execute_reply":"2023-12-07T11:46:31.869746Z","shell.execute_reply.started":"2023-12-07T11:46:26.211647Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import DistilBertModel, DistilBertTokenizer\n","from torch import cuda\n","\n","# Verify if cuda is enabled\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(f'Runs on {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:46:35.965362Z","iopub.status.busy":"2023-12-07T11:46:35.964841Z","iopub.status.idle":"2023-12-07T11:46:35.972144Z","shell.execute_reply":"2023-12-07T11:46:35.971001Z","shell.execute_reply.started":"2023-12-07T11:46:35.965327Z"},"trusted":true},"outputs":[],"source":["MAX_LEN = 512 # Max tokens\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 20\n","EPOCHS = 2\n","LEARNING_RATE = 1e-05\n","THRESHOLD = 0.5\n","TRAIN_BACKBONE = True # Specify if we train the backbone (DistilBERT) and the head or only the head"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:46:44.473293Z","iopub.status.busy":"2023-12-07T11:46:44.472890Z","iopub.status.idle":"2023-12-07T11:47:34.997374Z","shell.execute_reply":"2023-12-07T11:47:34.996381Z","shell.execute_reply.started":"2023-12-07T11:46:44.473260Z"},"trusted":true},"outputs":[],"source":["# Init wandb\n","\n","!pip install wandb\n","import wandb\n","\n","wandb.login()\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"wat-distilbert\",\n","    \n","    # track hyperparameters and run metadata\n","    config={\n","        \"learning_rate\": LEARNING_RATE,\n","        \"architecture\": \"distilbert\",\n","        \"epochs\": EPOCHS,\n","        \"train_distilbert\": TRAIN_BACKBONE,\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:47:48.162777Z","iopub.status.busy":"2023-12-07T11:47:48.162375Z","iopub.status.idle":"2023-12-07T11:47:48.291071Z","shell.execute_reply":"2023-12-07T11:47:48.289793Z","shell.execute_reply.started":"2023-12-07T11:47:48.162746Z"},"trusted":true},"outputs":[],"source":["id2label = {0: \"Irrelevant\", 1: \"Relevant\"}\n","label2id = {\"Irrelevant\": 0, \"Relevant\": 1}\n","\n","df = pd.read_csv('../data/WaTA_dataset.csv', encoding = \"ISO-8859-1\")\n","df['Class'] = df['Class'].apply(label2id.get)\n","df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:47:51.236574Z","iopub.status.busy":"2023-12-07T11:47:51.235811Z","iopub.status.idle":"2023-12-07T11:47:51.256095Z","shell.execute_reply":"2023-12-07T11:47:51.255081Z","shell.execute_reply.started":"2023-12-07T11:47:51.236533Z"},"trusted":true},"outputs":[],"source":["# Check dataset balance between relevant and irrelevant sentences\n","\n","def verify_data_balance(df):\n","    count = df['Class'].value_counts()\n","\n","    print(f'Number of irrelevant sentences: {count[0]}')\n","    print(f'Number of relevant sentences: {count[1]}')\n","    print(f'Percentage of irrelevant: {count[0] / (count[0] + count[1])}')\n","    print(f'Percentage of relevant: {count[1] / (count[0] + count[1])}')\n","    \n","verify_data_balance(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:47:53.544411Z","iopub.status.busy":"2023-12-07T11:47:53.544055Z","iopub.status.idle":"2023-12-07T11:47:53.554915Z","shell.execute_reply":"2023-12-07T11:47:53.553991Z","shell.execute_reply.started":"2023-12-07T11:47:53.544381Z"},"trusted":true},"outputs":[],"source":["# Define the torch dataset\n","\n","def tokenize(sentence, tokenizer):\n","    inputs = tokenizer.encode_plus(\n","        sentence,\n","        None,\n","        add_special_tokens=True,\n","        max_length=MAX_LEN,\n","        padding='max_length',\n","        truncation=True,\n","        return_token_type_ids=True\n","    )\n","    ids = inputs['input_ids']\n","    mask = inputs['attention_mask']\n","    return torch.tensor(ids, dtype=torch.long), torch.tensor(mask, dtype=torch.long)\n","\n","class RelevanceDataset(Dataset):\n","    def __init__(self, data, tokenizer):\n","        self.len = len(data)\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        \n","    def __getitem__(self, index):\n","        sentence = self.data.Sentence[index]\n","        \n","        ids, mask = tokenize(sentence, self.tokenizer)\n","\n","        return {\n","            'ids': ids,\n","            'mask': mask,\n","            'sentence': sentence,\n","            'targets': torch.tensor(self.data.Class[index], dtype=torch.float)\n","        } \n","    \n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:02.339889Z","iopub.status.busy":"2023-12-07T11:48:02.338864Z","iopub.status.idle":"2023-12-07T11:48:03.155633Z","shell.execute_reply":"2023-12-07T11:48:03.154354Z","shell.execute_reply.started":"2023-12-07T11:48:02.339857Z"},"trusted":true},"outputs":[],"source":["# Split dataset into training and test set and instantiate datasets for torch\n","\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n","\n","train_size = 0.9\n","train_dataset = df.sample(frac=train_size,random_state=200)\n","test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print('Train data balance:')\n","verify_data_balance(train_dataset)\n","print('Test data balance:')\n","verify_data_balance(test_dataset)\n","\n","print(\"FULL Dataset: {}\".format(df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = RelevanceDataset(train_dataset, tokenizer)\n","testing_set = RelevanceDataset(test_dataset, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:06.115781Z","iopub.status.busy":"2023-12-07T11:48:06.115421Z","iopub.status.idle":"2023-12-07T11:48:06.123568Z","shell.execute_reply":"2023-12-07T11:48:06.121977Z","shell.execute_reply.started":"2023-12-07T11:48:06.115754Z"},"trusted":true},"outputs":[],"source":["# Create data loaders, one for training and another for testing\n","\n","train_params = {\n","    'batch_size': TRAIN_BATCH_SIZE,\n","    'shuffle': True,\n","    'num_workers': 0\n","}\n","\n","test_params = {\n","    'batch_size': VALID_BATCH_SIZE,\n","    'shuffle': True,\n","    'num_workers': 0\n","}\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:09.740416Z","iopub.status.busy":"2023-12-07T11:48:09.740049Z","iopub.status.idle":"2023-12-07T11:48:09.750661Z","shell.execute_reply":"2023-12-07T11:48:09.749098Z","shell.execute_reply.started":"2023-12-07T11:48:09.740384Z"},"trusted":true},"outputs":[],"source":["# Define the binary classification model to discriminate between relevant or irrelevant sentences.\n","# The model uses DistilBERT as a backbone and a binary classification head\n","\n","class BinaryClassifier(torch.nn.Module):\n","    def __init__(self):\n","        super(BinaryClassifier, self).__init__()\n","        self.backbone = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","        self.head = torch.nn.Sequential(\n","            torch.nn.Linear(768, 768),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(768, 1),\n","            torch.nn.Sigmoid()\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        backbone_out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = backbone_out[0]\n","        return self.head(hidden_state[:, 0])\n","    \n","    def unfreeze_backbone(self):\n","        for param in self.backbone.parameters():\n","            param.requires_grad = True\n","            \n","    def freeze_backbone(self):\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:15.527168Z","iopub.status.busy":"2023-12-07T11:48:15.526809Z","iopub.status.idle":"2023-12-07T11:48:21.312627Z","shell.execute_reply":"2023-12-07T11:48:21.311512Z","shell.execute_reply.started":"2023-12-07T11:48:15.527139Z"},"trusted":true},"outputs":[],"source":["# Instantiate classification model and push it to the GPU\n","\n","model = BinaryClassifier()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T20:38:22.276327Z","iopub.status.busy":"2023-12-06T20:38:22.275387Z","iopub.status.idle":"2023-12-06T20:38:27.887942Z","shell.execute_reply":"2023-12-06T20:38:27.887041Z","shell.execute_reply.started":"2023-12-06T20:38:22.276283Z"},"trusted":true},"outputs":[],"source":["# Run this cell if you want to use pretrained classification model\n","# saved_model = wandb.restore('classifier.bin', run_path=\"wat-distilbert/ru3wl9xi\")8p404q8d\n","saved_model = wandb.restore('classifier.bin', run_path=\"wat-distilbert/a1ibmen6\") # Run comic-surf-18\n","#saved_tokenizer = wandb.restore('tokenizer.bin', run_path=\"wat-distilbert/ru3wl9xi\")\n","model = torch.load(saved_model.name)\n","model.to(device)\n","#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n","#loaded_tokenizer = loaded_tokenizer.load_vocabulary(saved_tokenizer.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:42.253181Z","iopub.status.busy":"2023-12-07T11:48:42.252140Z","iopub.status.idle":"2023-12-07T11:48:42.259808Z","shell.execute_reply":"2023-12-07T11:48:42.258599Z","shell.execute_reply.started":"2023-12-07T11:48:42.253147Z"},"trusted":true},"outputs":[],"source":["# Define loss and optimizer\n","loss_function = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:44.997627Z","iopub.status.busy":"2023-12-07T11:48:44.996939Z","iopub.status.idle":"2023-12-07T11:48:45.005496Z","shell.execute_reply":"2023-12-07T11:48:45.004147Z","shell.execute_reply.started":"2023-12-07T11:48:44.997594Z"},"trusted":true},"outputs":[],"source":["# Define metrics\n","\n","def compute_accuracy(tp, tn, fp, fn):\n","    return (tp + tn) / (tp + tn + fp + fn)\n","\n","def compute_precision(tp, fp):\n","    return tp / (tp + fp)\n","\n","def compute_recall(tp, fn):\n","    return tp / (tp + fn)\n","\n","def compute_f1(tp, fn, fp):\n","    return tp / (tp + (fn + fp) / 2)\n","\n","def pred_to_class(pred, threshold=0.5):\n","    return (pred >= THRESHOLD).float() "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:48:49.291650Z","iopub.status.busy":"2023-12-07T11:48:49.290917Z","iopub.status.idle":"2023-12-07T11:48:54.069832Z","shell.execute_reply":"2023-12-07T11:48:54.068816Z","shell.execute_reply.started":"2023-12-07T11:48:49.291618Z"},"trusted":true},"outputs":[],"source":["# Define method to visualize the results\n","\n","def test_example(model, tokenizer, nb_relevant=20, nb_irrelevant=20):\n","    for i in range(len(testing_set)):\n","        test_data = testing_set[i]\n","        ids, mask, sentence, target = test_data['ids'], test_data['mask'], test_data['sentence'], test_data[\"targets\"]\n","        if target.item() == 1:\n","            if nb_relevant > 0:\n","                nb_relevant -= 1\n","            else:\n","                continue\n","        elif target.item() == 0:\n","            if nb_irrelevant > 0:\n","                nb_irrelevant -= 1\n","            else:\n","                continue\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        outputs = model(ids, mask)\n","        pred_class = pred_to_class(outputs, THRESHOLD)\n","        print(sentence)\n","        print(f\"pred: {id2label[pred_class.item()]}, target: {id2label[target.item()]}\")\n","    \n","test_example(model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:49:10.519126Z","iopub.status.busy":"2023-12-07T11:49:10.518225Z","iopub.status.idle":"2023-12-07T11:49:10.534468Z","shell.execute_reply":"2023-12-07T11:49:10.533605Z","shell.execute_reply.started":"2023-12-07T11:49:10.519091Z"},"trusted":true},"outputs":[],"source":["# EVALUATION\n","\n","def evaluate():\n","    print(\"=========EVAL=========\")\n","    model.eval()\n","    tp, fp, fn, tn = 0, 0, 0, 0\n","    total_loss = 0\n","    nb_steps = 0\n","    with torch.no_grad():\n","        for i, data in enumerate(testing_loader):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float).reshape(-1, 1)\n","\n","            outputs = model(ids, mask)\n","            loss = loss_function(outputs, targets)\n","            total_loss += loss.item()\n","\n","            pred_class = pred_to_class(outputs, THRESHOLD)\n","            t_preds, t_targets = pred_class == 1, targets == 1\n","            f_preds, f_targets = pred_class == 0, targets == 0\n","            tp += (t_preds & t_targets).sum().item()\n","            fp += (t_preds & f_targets).sum().item()\n","            fn += (f_preds & t_targets).sum().item()\n","            tn += (f_preds & f_targets).sum().item()\n","\n","            nb_steps += 1\n","\n","            if i % 100 == 0:\n","                print(f\"Validation Loss per 100 steps: {loss.item()}\")\n","                print(f\"Validation Accuracy per 100 steps: {compute_accuracy(tp, tn, fp, fn)}\")\n","                print(f\"Validation Precision per 100 steps: {compute_precision(tp, fp)}\")\n","                print(f\"Validation Recall per 100 steps: {compute_recall(tp, fn)}\")\n","                print(f\"Validation f1 per 500 steps: {compute_f1(tp, fn, fp)}\")\n","\n","    avg_loss = total_loss / nb_steps\n","    accuracy = compute_accuracy(tp, tn, fp, fn)\n","    precision = compute_precision(tp, fp)\n","    recall = compute_recall(tp, fn)\n","    f1 = compute_f1(tp, fn, fp)\n","    wandb.log({\"eval_loss\": avg_loss, \"eval_accuracy\": accuracy, \"eval_precision\": precision, \"eval_recall\": recall, \"eval_f1\": f1})\n","    print(f\"Avg loss: {avg_loss}\")\n","    print(f\"Accuracy: {accuracy}\")\n","    print(f\"Precision: {precision}\")\n","    print(f\"Recall: {recall}\")\n","    print(f\"f1: {f1}\")\n","    \n","    print(\"=========END EVAL=========\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:49:31.846908Z","iopub.status.busy":"2023-12-07T11:49:31.846543Z","iopub.status.idle":"2023-12-07T12:22:39.333083Z","shell.execute_reply":"2023-12-07T12:22:39.332012Z","shell.execute_reply.started":"2023-12-07T11:49:31.846878Z"},"trusted":true},"outputs":[],"source":["# TRAINING\n","\n","if TRAIN_BACKBONE:\n","    model.unfreeze_backbone()\n","\n","for i in range(EPOCHS):\n","    total_loss = 0\n","    nb_steps = 0\n","    tp, fp, fn, tn = 0, 0, 0, 0 \n","    model.train()\n","    for j,data in enumerate(training_loader):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float).reshape(-1, 1)\n","\n","        outputs = model(ids, mask)\n","        loss = loss_function(outputs, targets)\n","        total_loss += loss.item()\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        pred_class = pred_to_class(outputs, THRESHOLD)\n","        t_preds, t_targets = pred_class == 1, targets == 1\n","        f_preds, f_targets = pred_class == 0, targets == 0\n","        tp += (t_preds & t_targets).sum().item()\n","        fp += (t_preds & f_targets).sum().item()\n","        fn += (f_preds & t_targets).sum().item()\n","        tn += (f_preds & f_targets).sum().item()\n","        \n","        nb_steps += 1\n","        \n","        if j > 0 and j % 500 == 0:\n","            print(f\"Training Loss per 500 steps: {loss.item()}\")\n","            print(f\"Training Accuracy per 500 steps: {compute_accuracy(tp, tn, fp, fn)}\")\n","            print(f\"Training Precision per 500 steps: {compute_precision(tp, fp)}\")\n","            print(f\"Training Recall per 500 steps: {compute_recall(tp, fn)}\")\n","            print(f\"Training f1 per 500 steps: {compute_f1(tp, fn, fp)}\")\n","    \n","    avg_loss = total_loss / nb_steps\n","    accuracy = compute_accuracy(tp, tn, fp, fn)\n","    precision = compute_precision(tp, fp)\n","    recall = compute_recall(tp, fn)\n","    f1 = compute_f1(tp, fn, fp)\n","    wandb.log({\"loss\": avg_loss, \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1})\n","    print(f\"Epoch {i}, avg loss: {avg_loss}\")\n","    print(f\"Epoch {i}, accuracy: {accuracy}\")\n","    print(f\"Epoch {i}, precision: {precision}\")\n","    print(f\"Epoch {i}, recall: {recall}\")\n","    print(f\"Epoch {i}, f1: {f1}\")\n","    evaluate()\n","    \n","    \n","    test_example(model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate current model\n","evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T13:01:44.737853Z","iopub.status.busy":"2023-12-07T13:01:44.737231Z","iopub.status.idle":"2023-12-07T13:01:45.670824Z","shell.execute_reply":"2023-12-07T13:01:45.669503Z","shell.execute_reply.started":"2023-12-07T13:01:44.737817Z"},"trusted":true},"outputs":[],"source":["# Save model to wandb\n","\n","import os\n","\n","out_model = os.path.join(wandb.run.dir, \"classifier.bin\")\n","out_tokenizer = os.path.join(wandb.run.dir, \"tokenizer.bin\")\n","\n","torch.save(model, out_model)\n","tokenizer.save_vocabulary(out_tokenizer)\n","\n","wandb.save('classifier.bin')\n","wandb.save('tokenizer.bin')\n","\n","out_model_pt = os.path.join(wandb.run.dir, \"classifier.pt\")\n","torch.save(model.state_dict(), out_model_pt)\n","\n","wandb.save('classifier.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T13:01:26.706815Z","iopub.status.busy":"2023-12-07T13:01:26.706466Z","iopub.status.idle":"2023-12-07T13:01:28.885212Z","shell.execute_reply":"2023-12-07T13:01:28.884286Z","shell.execute_reply.started":"2023-12-07T13:01:26.706788Z"},"trusted":true},"outputs":[],"source":["test_example(model, tokenizer, 8, 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T11:38:16.607605Z","iopub.status.busy":"2023-12-07T11:38:16.606707Z","iopub.status.idle":"2023-12-07T11:38:19.981061Z","shell.execute_reply":"2023-12-07T11:38:19.980170Z","shell.execute_reply.started":"2023-12-07T11:38:16.607571Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["THRESHOLD TESTS\n","\n","THRESHOLD: 0.5\n","\n","Avg loss: 0.7038330654244102 \\\n","Accuracy: 0.8570290720828355 \\\n","Precision: 0.8728854519091348 \\\n","Recall: 0.9495268138801262 \\\n","f1: 0.9095945605640896\n","\n","(icy-silence-9) \\\n","Avg loss: 0.831273452559438 \\\n","Accuracy: 0.8410991636798089 \\\n","Precision: 0.9219539584503088 \\\n","Recall: 0.8633017875920084 \\\n","f1: 0.8916644040184633\n","\n","(different-dream-10) \\\n","Avg loss: 0.5872668912708168 \\\n","Accuracy: 0.8614097968936678 \\\n","Precision: 0.8940162271805274 \\\n","Recall: 0.926919032597266 \\\n","f1: 0.9101703665462054\n","\n","(worthy-breeze-12) \\\n","Avg loss: 0.9387986349253287 \\\n","Accuracy: 0.8566308243727598 \\\n","Precision: 0.8933673469387755 \\\n","Recall: 0.9206098843322819 \\\n","f1: 0.9067840497151735\n","\n","(frosty-star-13) \\\n","Avg loss: 0.3630746433008758 \\\n","Accuracy: 0.8546395858223815 \\\n","Precision: 0.881011403073872 \\\n","Recall: 0.9342797055730809 \\\n","f1: 0.9068639959173258\n","\n","(volcanic-thunder-14) \\\n","Avg loss: 0.3518915092129083 \\\n","Accuracy: 0.8630027877339705 \\\n","Precision: 0.8841222879684418 \\\n","Recall: 0.9426919032597266 \\\n","f1: 0.9124681933842239\n","\n","THRESHOLD: 0.6\n","\n","Avg loss: 0.7061429985850636 \\\n","Accuracy: 0.8554360812425329 \\\n","Precision: 0.8759159745969711 \\\n","Recall: 0.9426919032597266 \\\n","f1: 0.9080779944289693\n","\n","THRESHOLD: 0.7\n","\n","Avg loss: 0.7037493148331239 \\\n","Accuracy: 0.8566308243727598 \\\n","Precision: 0.8801775147928994 \\\n","Recall: 0.9384858044164038 \\\n","f1: 0.9083969465648855\n","\n","THRESHOLD: 0.8\n","\n","Avg loss: 0.7040119320611536 \\\n","Accuracy: 0.8566308243727598 \\\n","Precision: 0.8847305389221557 \\\n","Recall: 0.9321766561514195 \\\n","f1: 0.9078341013824884\n","\n","**THRESHOLD: 0.9**\n","\n","Avg loss: 0.7037559155104978 \\\n","Accuracy: 0.8610115491835922 \\\n","Precision: 0.8955680081507896 \\\n","Recall: 0.9242902208201893 \\\n","f1: 0.9097024579560156\n","\n","(volcanic-thunder-14) \\\n","Avg loss: 0.35272171691296594 \\\n","Accuracy: 0.8351254480286738 \\\n","Precision: 0.9355971896955504 \\\n","Recall: 0.8401682439537329 \\\n","f1: 0.8853185595567867\n","\n","THRESHOLD: 0.95\n","\n","Avg loss: 0.7070154592197108 \\\n","Accuracy: 0.8582238152130626 \\\n","Precision: 0.9017671517671517 \\\n","Recall: 0.9121976866456362 \\\n","f1: 0.9069524307370622"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4115314,"sourceId":7132584,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
