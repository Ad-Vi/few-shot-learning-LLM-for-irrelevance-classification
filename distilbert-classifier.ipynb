{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7132584,"sourceType":"datasetVersion","datasetId":4115314}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertModel, DistilBertTokenizer\nfrom torch import cuda\n\n# Verify if cuda is enabled\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(f'Runs on {device}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T11:46:26.211110Z","iopub.execute_input":"2023-12-07T11:46:26.211683Z","iopub.status.idle":"2023-12-07T11:46:31.870845Z","shell.execute_reply.started":"2023-12-07T11:46:26.211647Z","shell.execute_reply":"2023-12-07T11:46:31.869746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512 # Max tokens\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 20\nEPOCHS = 2\nLEARNING_RATE = 1e-05\nTHRESHOLD = 0.5\nTRAIN_BACKBONE = True # Specify if we train the backbone (DistilBERT) and the head or only the head","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:46:35.964841Z","iopub.execute_input":"2023-12-07T11:46:35.965362Z","iopub.status.idle":"2023-12-07T11:46:35.972144Z","shell.execute_reply.started":"2023-12-07T11:46:35.965327Z","shell.execute_reply":"2023-12-07T11:46:35.971001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Init wandb\n\n!pip install wandb\nimport wandb\n\nwandb.login()\nwandb.init(\n    # set the wandb project where this run will be logged\n    project=\"wat-distilbert\",\n    \n    # track hyperparameters and run metadata\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"architecture\": \"distilbert\",\n        \"epochs\": EPOCHS,\n        \"train_distilbert\": TRAIN_BACKBONE,\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:46:44.472890Z","iopub.execute_input":"2023-12-07T11:46:44.473293Z","iopub.status.idle":"2023-12-07T11:47:34.997374Z","shell.execute_reply.started":"2023-12-07T11:46:44.473260Z","shell.execute_reply":"2023-12-07T11:47:34.996381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load CSV dataset and encode classes\n\nid2label = {0: \"Irrelevant\", 1: \"Relevant\"}\nlabel2id = {\"Irrelevant\": 0, \"Relevant\": 1}\n\ndf = pd.read_csv('/kaggle/input/sentence-relevance/sentence_relevance.csv', encoding = \"ISO-8859-1\")\ndf['Class'] = df['Class'].apply(label2id.get)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:47:48.162375Z","iopub.execute_input":"2023-12-07T11:47:48.162777Z","iopub.status.idle":"2023-12-07T11:47:48.291071Z","shell.execute_reply.started":"2023-12-07T11:47:48.162746Z","shell.execute_reply":"2023-12-07T11:47:48.289793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check dataset balance between relevant and irrelevant sentences\n\ndef verify_data_balance(df):\n    count = df['Class'].value_counts()\n\n    print(f'Number of irrelevant sentences: {count[0]}')\n    print(f'Number of relevant sentences: {count[1]}')\n    print(f'Percentage of irrelevant: {count[0] / (count[0] + count[1])}')\n    print(f'Percentage of relevant: {count[1] / (count[0] + count[1])}')\n    \nverify_data_balance(df)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:47:51.235811Z","iopub.execute_input":"2023-12-07T11:47:51.236574Z","iopub.status.idle":"2023-12-07T11:47:51.256095Z","shell.execute_reply.started":"2023-12-07T11:47:51.236533Z","shell.execute_reply":"2023-12-07T11:47:51.255081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the torch dataset\n\ndef tokenize(sentence, tokenizer):\n    inputs = tokenizer.encode_plus(\n        sentence,\n        None,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_token_type_ids=True\n    )\n    ids = inputs['input_ids']\n    mask = inputs['attention_mask']\n    return torch.tensor(ids, dtype=torch.long), torch.tensor(mask, dtype=torch.long)\n\nclass RelevanceDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.len = len(data)\n        self.data = data\n        self.tokenizer = tokenizer\n        \n    def __getitem__(self, index):\n        sentence = self.data.Sentence[index]\n        \n        ids, mask = tokenize(sentence, self.tokenizer)\n\n        return {\n            'ids': ids,\n            'mask': mask,\n            'sentence': sentence,\n            'targets': torch.tensor(self.data.Class[index], dtype=torch.float)\n        } \n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:47:53.544055Z","iopub.execute_input":"2023-12-07T11:47:53.544411Z","iopub.status.idle":"2023-12-07T11:47:53.554915Z","shell.execute_reply.started":"2023-12-07T11:47:53.544381Z","shell.execute_reply":"2023-12-07T11:47:53.553991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training and test set and instantiate datasets for torch\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n\ntrain_size = 0.9\ntrain_dataset = df.sample(frac=train_size,random_state=200)\ntest_dataset = df.drop(train_dataset.index).reset_index(drop=True)\ntrain_dataset = train_dataset.reset_index(drop=True)\n\nprint('Train data balance:')\nverify_data_balance(train_dataset)\nprint('Test data balance:')\nverify_data_balance(test_dataset)\n\nprint(\"FULL Dataset: {}\".format(df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = RelevanceDataset(train_dataset, tokenizer)\ntesting_set = RelevanceDataset(test_dataset, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:02.338864Z","iopub.execute_input":"2023-12-07T11:48:02.339889Z","iopub.status.idle":"2023-12-07T11:48:03.155633Z","shell.execute_reply.started":"2023-12-07T11:48:02.339857Z","shell.execute_reply":"2023-12-07T11:48:03.154354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create data loaders, one for training and another for testing\n\ntrain_params = {\n    'batch_size': TRAIN_BATCH_SIZE,\n    'shuffle': True,\n    'num_workers': 0\n}\n\ntest_params = {\n    'batch_size': VALID_BATCH_SIZE,\n    'shuffle': True,\n    'num_workers': 0\n}\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:06.115421Z","iopub.execute_input":"2023-12-07T11:48:06.115781Z","iopub.status.idle":"2023-12-07T11:48:06.123568Z","shell.execute_reply.started":"2023-12-07T11:48:06.115754Z","shell.execute_reply":"2023-12-07T11:48:06.121977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the binary classification model to discriminate between relevant or irrelevant sentences.\n# The model uses DistilBERT as a backbone and a binary classification head\n\nclass BinaryClassifier(torch.nn.Module):\n    def __init__(self):\n        super(BinaryClassifier, self).__init__()\n        self.backbone = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.head = torch.nn.Sequential(\n            torch.nn.Linear(768, 768),\n            torch.nn.ReLU(),\n            torch.nn.Linear(768, 1),\n            torch.nn.Sigmoid()\n        )\n\n    def forward(self, input_ids, attention_mask):\n        backbone_out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = backbone_out[0]\n        return self.head(hidden_state[:, 0])\n    \n    def unfreeze_backbone(self):\n        for param in self.backbone.parameters():\n            param.requires_grad = True\n            \n    def freeze_backbone(self):\n        for param in self.backbone.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:09.740049Z","iopub.execute_input":"2023-12-07T11:48:09.740416Z","iopub.status.idle":"2023-12-07T11:48:09.750661Z","shell.execute_reply.started":"2023-12-07T11:48:09.740384Z","shell.execute_reply":"2023-12-07T11:48:09.749098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate classification model and push it to the GPU\n\nmodel = BinaryClassifier()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:15.526809Z","iopub.execute_input":"2023-12-07T11:48:15.527168Z","iopub.status.idle":"2023-12-07T11:48:21.312627Z","shell.execute_reply.started":"2023-12-07T11:48:15.527139Z","shell.execute_reply":"2023-12-07T11:48:21.311512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run this cell if you want to use pretrained classification model\n# saved_model = wandb.restore('classifier.bin', run_path=\"wat-distilbert/ru3wl9xi\")8p404q8d\nsaved_model = wandb.restore('classifier.bin', run_path=\"wat-distilbert/a1ibmen6\") # Run comic-surf-18\n#saved_tokenizer = wandb.restore('tokenizer.bin', run_path=\"wat-distilbert/ru3wl9xi\")\nmodel = torch.load(saved_model.name)\nmodel.to(device)\n#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n#loaded_tokenizer = loaded_tokenizer.load_vocabulary(saved_tokenizer.name)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T20:38:22.275387Z","iopub.execute_input":"2023-12-06T20:38:22.276327Z","iopub.status.idle":"2023-12-06T20:38:27.887942Z","shell.execute_reply.started":"2023-12-06T20:38:22.276283Z","shell.execute_reply":"2023-12-06T20:38:27.887041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss and optimizer\nloss_function = torch.nn.BCELoss()\noptimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:42.252140Z","iopub.execute_input":"2023-12-07T11:48:42.253181Z","iopub.status.idle":"2023-12-07T11:48:42.259808Z","shell.execute_reply.started":"2023-12-07T11:48:42.253147Z","shell.execute_reply":"2023-12-07T11:48:42.258599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define metrics\n\ndef compute_accuracy(tp, tn, fp, fn):\n    return (tp + tn) / (tp + tn + fp + fn)\n\ndef compute_precision(tp, fp):\n    return tp / (tp + fp)\n\ndef compute_recall(tp, fn):\n    return tp / (tp + fn)\n\ndef compute_f1(tp, fn, fp):\n    return tp / (tp + (fn + fp) / 2)\n\ndef pred_to_class(pred, threshold=0.5):\n    return (pred >= THRESHOLD).float() ","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:44.996939Z","iopub.execute_input":"2023-12-07T11:48:44.997627Z","iopub.status.idle":"2023-12-07T11:48:45.005496Z","shell.execute_reply.started":"2023-12-07T11:48:44.997594Z","shell.execute_reply":"2023-12-07T11:48:45.004147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define method to visualize the results\n\ndef test_example(model, tokenizer, nb_relevant=20, nb_irrelevant=20):\n    for i in range(len(testing_set)):\n        test_data = testing_set[i]\n        ids, mask, sentence, target = test_data['ids'], test_data['mask'], test_data['sentence'], test_data[\"targets\"]\n        if target.item() == 1:\n            if nb_relevant > 0:\n                nb_relevant -= 1\n            else:\n                continue\n        elif target.item() == 0:\n            if nb_irrelevant > 0:\n                nb_irrelevant -= 1\n            else:\n                continue\n        ids = ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        outputs = model(ids, mask)\n        pred_class = pred_to_class(outputs, THRESHOLD)\n        print(sentence)\n        print(f\"pred: {id2label[pred_class.item()]}, target: {id2label[target.item()]}\")\n    \ntest_example(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:48:49.290917Z","iopub.execute_input":"2023-12-07T11:48:49.291650Z","iopub.status.idle":"2023-12-07T11:48:54.069832Z","shell.execute_reply.started":"2023-12-07T11:48:49.291618Z","shell.execute_reply":"2023-12-07T11:48:54.068816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EVALUATION\n\ndef evaluate():\n    print(\"=========EVAL=========\")\n    model.eval()\n    tp, fp, fn, tn = 0, 0, 0, 0\n    total_loss = 0\n    nb_steps = 0\n    with torch.no_grad():\n        for i, data in enumerate(testing_loader):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float).reshape(-1, 1)\n\n            outputs = model(ids, mask)\n            loss = loss_function(outputs, targets)\n            total_loss += loss.item()\n\n            pred_class = pred_to_class(outputs, THRESHOLD)\n            t_preds, t_targets = pred_class == 1, targets == 1\n            f_preds, f_targets = pred_class == 0, targets == 0\n            tp += (t_preds & t_targets).sum().item()\n            fp += (t_preds & f_targets).sum().item()\n            fn += (f_preds & t_targets).sum().item()\n            tn += (f_preds & f_targets).sum().item()\n\n            nb_steps += 1\n\n            if i % 100 == 0:\n                print(f\"Validation Loss per 100 steps: {loss.item()}\")\n                print(f\"Validation Accuracy per 100 steps: {compute_accuracy(tp, tn, fp, fn)}\")\n                print(f\"Validation Precision per 100 steps: {compute_precision(tp, fp)}\")\n                print(f\"Validation Recall per 100 steps: {compute_recall(tp, fn)}\")\n                print(f\"Validation f1 per 500 steps: {compute_f1(tp, fn, fp)}\")\n\n    avg_loss = total_loss / nb_steps\n    accuracy = compute_accuracy(tp, tn, fp, fn)\n    precision = compute_precision(tp, fp)\n    recall = compute_recall(tp, fn)\n    f1 = compute_f1(tp, fn, fp)\n    wandb.log({\"eval_loss\": avg_loss, \"eval_accuracy\": accuracy, \"eval_precision\": precision, \"eval_recall\": recall, \"eval_f1\": f1})\n    print(f\"Avg loss: {avg_loss}\")\n    print(f\"Accuracy: {accuracy}\")\n    print(f\"Precision: {precision}\")\n    print(f\"Recall: {recall}\")\n    print(f\"f1: {f1}\")\n    \n    print(\"=========END EVAL=========\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:49:10.518225Z","iopub.execute_input":"2023-12-07T11:49:10.519126Z","iopub.status.idle":"2023-12-07T11:49:10.534468Z","shell.execute_reply.started":"2023-12-07T11:49:10.519091Z","shell.execute_reply":"2023-12-07T11:49:10.533605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAINING\n\nif TRAIN_BACKBONE:\n    model.unfreeze_backbone()\n\nfor i in range(EPOCHS):\n    total_loss = 0\n    nb_steps = 0\n    tp, fp, fn, tn = 0, 0, 0, 0 \n    model.train()\n    for j,data in enumerate(training_loader):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float).reshape(-1, 1)\n\n        outputs = model(ids, mask)\n        loss = loss_function(outputs, targets)\n        total_loss += loss.item()\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        pred_class = pred_to_class(outputs, THRESHOLD)\n        t_preds, t_targets = pred_class == 1, targets == 1\n        f_preds, f_targets = pred_class == 0, targets == 0\n        tp += (t_preds & t_targets).sum().item()\n        fp += (t_preds & f_targets).sum().item()\n        fn += (f_preds & t_targets).sum().item()\n        tn += (f_preds & f_targets).sum().item()\n        \n        nb_steps += 1\n        \n        if j > 0 and j % 500 == 0:\n            print(f\"Training Loss per 500 steps: {loss.item()}\")\n            print(f\"Training Accuracy per 500 steps: {compute_accuracy(tp, tn, fp, fn)}\")\n            print(f\"Training Precision per 500 steps: {compute_precision(tp, fp)}\")\n            print(f\"Training Recall per 500 steps: {compute_recall(tp, fn)}\")\n            print(f\"Training f1 per 500 steps: {compute_f1(tp, fn, fp)}\")\n    \n    avg_loss = total_loss / nb_steps\n    accuracy = compute_accuracy(tp, tn, fp, fn)\n    precision = compute_precision(tp, fp)\n    recall = compute_recall(tp, fn)\n    f1 = compute_f1(tp, fn, fp)\n    wandb.log({\"loss\": avg_loss, \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1})\n    print(f\"Epoch {i}, avg loss: {avg_loss}\")\n    print(f\"Epoch {i}, accuracy: {accuracy}\")\n    print(f\"Epoch {i}, precision: {precision}\")\n    print(f\"Epoch {i}, recall: {recall}\")\n    print(f\"Epoch {i}, f1: {f1}\")\n    evaluate()\n    \n    \n    test_example(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:49:31.846543Z","iopub.execute_input":"2023-12-07T11:49:31.846908Z","iopub.status.idle":"2023-12-07T12:22:39.333083Z","shell.execute_reply.started":"2023-12-07T11:49:31.846878Z","shell.execute_reply":"2023-12-07T12:22:39.332012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate current model\nevaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model to wandb\n\nimport os\n\nout_model = os.path.join(wandb.run.dir, \"classifier.bin\")\nout_tokenizer = os.path.join(wandb.run.dir, \"tokenizer.bin\")\n\ntorch.save(model, out_model)\ntokenizer.save_vocabulary(out_tokenizer)\n\nwandb.save('classifier.bin')\nwandb.save('tokenizer.bin')\n\nout_model_pt = os.path.join(wandb.run.dir, \"classifier.pt\")\ntorch.save(model.state_dict(), out_model_pt)\n\nwandb.save('classifier.pt')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:01:44.737231Z","iopub.execute_input":"2023-12-07T13:01:44.737853Z","iopub.status.idle":"2023-12-07T13:01:45.670824Z","shell.execute_reply.started":"2023-12-07T13:01:44.737817Z","shell.execute_reply":"2023-12-07T13:01:45.669503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_example(model, tokenizer, 8, 8)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:01:26.706466Z","iopub.execute_input":"2023-12-07T13:01:26.706815Z","iopub.status.idle":"2023-12-07T13:01:28.885212Z","shell.execute_reply.started":"2023-12-07T13:01:26.706788Z","shell.execute_reply":"2023-12-07T13:01:28.884286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:38:16.606707Z","iopub.execute_input":"2023-12-07T11:38:16.607605Z","iopub.status.idle":"2023-12-07T11:38:19.981061Z","shell.execute_reply.started":"2023-12-07T11:38:16.607571Z","shell.execute_reply":"2023-12-07T11:38:19.980170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THRESHOLD TESTS\n\nTHRESHOLD: 0.5\n\nAvg loss: 0.7038330654244102 \\\nAccuracy: 0.8570290720828355 \\\nPrecision: 0.8728854519091348 \\\nRecall: 0.9495268138801262 \\\nf1: 0.9095945605640896\n\n(icy-silence-9) \\\nAvg loss: 0.831273452559438 \\\nAccuracy: 0.8410991636798089 \\\nPrecision: 0.9219539584503088 \\\nRecall: 0.8633017875920084 \\\nf1: 0.8916644040184633\n\n(different-dream-10) \\\nAvg loss: 0.5872668912708168 \\\nAccuracy: 0.8614097968936678 \\\nPrecision: 0.8940162271805274 \\\nRecall: 0.926919032597266 \\\nf1: 0.9101703665462054\n\n(worthy-breeze-12) \\\nAvg loss: 0.9387986349253287 \\\nAccuracy: 0.8566308243727598 \\\nPrecision: 0.8933673469387755 \\\nRecall: 0.9206098843322819 \\\nf1: 0.9067840497151735\n\n(frosty-star-13) \\\nAvg loss: 0.3630746433008758 \\\nAccuracy: 0.8546395858223815 \\\nPrecision: 0.881011403073872 \\\nRecall: 0.9342797055730809 \\\nf1: 0.9068639959173258\n\n(volcanic-thunder-14) \\\nAvg loss: 0.3518915092129083 \\\nAccuracy: 0.8630027877339705 \\\nPrecision: 0.8841222879684418 \\\nRecall: 0.9426919032597266 \\\nf1: 0.9124681933842239\n\nTHRESHOLD: 0.6\n\nAvg loss: 0.7061429985850636 \\\nAccuracy: 0.8554360812425329 \\\nPrecision: 0.8759159745969711 \\\nRecall: 0.9426919032597266 \\\nf1: 0.9080779944289693\n\nTHRESHOLD: 0.7\n\nAvg loss: 0.7037493148331239 \\\nAccuracy: 0.8566308243727598 \\\nPrecision: 0.8801775147928994 \\\nRecall: 0.9384858044164038 \\\nf1: 0.9083969465648855\n\nTHRESHOLD: 0.8\n\nAvg loss: 0.7040119320611536 \\\nAccuracy: 0.8566308243727598 \\\nPrecision: 0.8847305389221557 \\\nRecall: 0.9321766561514195 \\\nf1: 0.9078341013824884\n\n**THRESHOLD: 0.9**\n\nAvg loss: 0.7037559155104978 \\\nAccuracy: 0.8610115491835922 \\\nPrecision: 0.8955680081507896 \\\nRecall: 0.9242902208201893 \\\nf1: 0.9097024579560156\n\n(volcanic-thunder-14) \\\nAvg loss: 0.35272171691296594 \\\nAccuracy: 0.8351254480286738 \\\nPrecision: 0.9355971896955504 \\\nRecall: 0.8401682439537329 \\\nf1: 0.8853185595567867\n\nTHRESHOLD: 0.95\n\nAvg loss: 0.7070154592197108 \\\nAccuracy: 0.8582238152130626 \\\nPrecision: 0.9017671517671517 \\\nRecall: 0.9121976866456362 \\\nf1: 0.9069524307370622","metadata":{}}]}