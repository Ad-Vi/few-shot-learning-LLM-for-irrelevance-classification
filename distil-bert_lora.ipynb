{"cells":[{"cell_type":"code","execution_count":70,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-04T21:44:20.173734Z","iopub.status.busy":"2023-12-04T21:44:20.173105Z","iopub.status.idle":"2023-12-04T21:44:51.713438Z","shell.execute_reply":"2023-12-04T21:44:51.711784Z","shell.execute_reply.started":"2023-12-04T21:44:20.173682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: peft in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (0.6.2)\n","Requirement already satisfied: numpy>=1.17 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (23.1)\n","Requirement already satisfied: psutil in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (5.9.0)\n","Requirement already satisfied: pyyaml in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (6.0)\n","Requirement already satisfied: torch>=1.13.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (2.0.1)\n","Requirement already satisfied: transformers in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (4.32.1)\n","Requirement already satisfied: tqdm in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (4.66.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (0.25.0)\n","Requirement already satisfied: safetensors in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from peft) (0.4.0)\n","Requirement already satisfied: huggingface-hub in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from accelerate>=0.21.0->peft) (0.19.4)\n","Requirement already satisfied: filelock in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.9.0)\n","Requirement already satisfied: typing-extensions in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from torch>=1.13.0->peft) (4.5.0)\n","Requirement already satisfied: sympy in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.11.1)\n","Requirement already satisfied: networkx in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.8.4)\n","Requirement already satisfied: jinja2 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from transformers->peft) (2023.10.3)\n","Requirement already satisfied: requests in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from transformers->peft) (2.29.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from transformers->peft) (0.13.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests->transformers->peft) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests->transformers->peft) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests->transformers->peft) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests->transformers->peft) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.2.1)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: evaluate in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (2.14.7)\n","Requirement already satisfied: numpy>=1.17 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (1.24.3)\n","Requirement already satisfied: dill in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (2.1.1)\n","Requirement already satisfied: requests>=2.19.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (2.29.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: multiprocess in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (2023.10.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (0.19.4)\n","Requirement already satisfied: packaging in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (23.1)\n","Requirement already satisfied: responses<0.19 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: filelock in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /home/deimort/miniconda3/envs/deep_learning/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"]}],"source":["!pip install peft\n","!pip install evaluate"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T21:44:51.716988Z","iopub.status.busy":"2023-12-04T21:44:51.716518Z","iopub.status.idle":"2023-12-04T21:44:51.726215Z","shell.execute_reply":"2023-12-04T21:44:51.724853Z","shell.execute_reply.started":"2023-12-04T21:44:51.716947Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import transformers\n","import torch\n","import wandb\n","\n","from datasets import load_dataset, DatasetDict, Dataset\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig, \n","    AutoModelForSequenceClassification,\n","    DataCollatorWithPadding,\n","    TrainingArguments,\n","    Trainer)\n","\n","from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n","import evaluate\n","import torch\n","import numpy as np\n","import pandas as pd\n","import random"]},{"cell_type":"code","execution_count":72,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-04T21:44:51.728158Z","iopub.status.busy":"2023-12-04T21:44:51.727739Z","iopub.status.idle":"2023-12-04T21:44:51.885195Z","shell.execute_reply":"2023-12-04T21:44:51.883945Z","shell.execute_reply.started":"2023-12-04T21:44:51.728107Z"},"trusted":true},"outputs":[],"source":["# model_name = \"tiiuae/falcon-7b\"\n","# model_name = \"tiiuae/falcon-rw-1b\"\n","model_name = \"distilbert-base-uncased\"\n","# mistral = \"mistralai/Mistral-7B-v0.1\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T21:44:51.888333Z","iopub.status.busy":"2023-12-04T21:44:51.887931Z","iopub.status.idle":"2023-12-04T21:44:52.922102Z","shell.execute_reply":"2023-12-04T21:44:52.920797Z","shell.execute_reply.started":"2023-12-04T21:44:51.888298Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# define label maps\n","id2label = {0: \"Irrelevant\", 1: \"Relevant\"}\n","label2id = {\"Irrelevant\":0, \"Relevant\":1}\n","\n","# generate classification model from model_checkpoint\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name, num_labels=2, id2label=id2label, label2id=label2id)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T21:44:52.923821Z","iopub.status.busy":"2023-12-04T21:44:52.923431Z","iopub.status.idle":"2023-12-04T21:44:52.987914Z","shell.execute_reply":"2023-12-04T21:44:52.986665Z","shell.execute_reply.started":"2023-12-04T21:44:52.923789Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Class: 0\n"]}],"source":["# Tokenize input text\n","input_text = \"Hello\"\n","inputs = tokenizer(input_text, return_tensors=\"pt\")\n","\n","# Inference\n","outputs = model(**inputs)\n","\n","# Post-processing\n","logits = outputs.logits\n","predicted_class = torch.argmax(logits, dim=1).item()\n","print(\"Predicted Class:\", predicted_class)"]},{"cell_type":"markdown","metadata":{},"source":["# Low Rank Adaptation Fine Tuning"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Gathering"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T21:44:53.036135Z","iopub.status.busy":"2023-12-04T21:44:53.035791Z","iopub.status.idle":"2023-12-04T21:44:53.278180Z","shell.execute_reply":"2023-12-04T21:44:53.271977Z","shell.execute_reply.started":"2023-12-04T21:44:53.036106Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('../data/WaTA_dataset.csv', encoding = \"ISO-8859-1\")\n","\n","test_set = 0.3\n","\n","x_train, y_train, x_test, y_test = [], [], [] ,[]\n","relevant_sentences, irrelevant_sentences = [], []\n","\n","for index, row in df.iterrows():\n","    if row['Class'] == 'Relevant':\n","        relevant_sentences.append(row['Sentence'])\n","    else:\n","        irrelevant_sentences.append(row['Sentence'])\n","\n","random.shuffle(relevant_sentences)\n","random.shuffle(irrelevant_sentences)\n","\n","relevant_train = relevant_sentences[:int(len(relevant_sentences)*(1-test_set))]\n","relevant_test = relevant_sentences[int(len(relevant_sentences)*(1-test_set)):]\n","irrelevant_train = irrelevant_sentences[:int(len(irrelevant_sentences)*(1-test_set))]\n","irrelevant_test = irrelevant_sentences[int(len(irrelevant_sentences)*(1-test_set)):]\n","\n","for sentence in relevant_train:\n","    x_train.append(sentence)\n","    y_train.append(1)\n","    \n","for sentence in irrelevant_train:\n","    x_train.append(sentence)\n","    y_train.append(0)\n","\n","for sentence in relevant_test:\n","    x_test.append(sentence)\n","    y_test.append(1)\n","    \n","for sentence in irrelevant_test:\n","    x_test.append(sentence)\n","    y_test.append(0)       \n","        \n","dataset = DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n","                        'test':Dataset.from_dict({'label':y_test,'text':x_test})})"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.279671Z","iopub.status.idle":"2023-12-04T21:44:53.280653Z","shell.execute_reply":"2023-12-04T21:44:53.280256Z","shell.execute_reply.started":"2023-12-04T21:44:53.280214Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text'],\n","        num_rows: 17577\n","    })\n","    test: Dataset({\n","        features: ['label', 'text'],\n","        num_rows: 7534\n","    })\n","})"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess data"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.283144Z","iopub.status.idle":"2023-12-04T21:44:53.283878Z","shell.execute_reply":"2023-12-04T21:44:53.283580Z","shell.execute_reply.started":"2023-12-04T21:44:53.283549Z"},"trusted":true},"outputs":[],"source":["# add pad token if none exists\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.286760Z","iopub.status.idle":"2023-12-04T21:44:53.287951Z","shell.execute_reply":"2023-12-04T21:44:53.287745Z","shell.execute_reply.started":"2023-12-04T21:44:53.287719Z"},"trusted":true},"outputs":[],"source":["# create tokenize function\n","def tokenize_function(examples):\n","    # extract text\n","    text = examples[\"text\"]\n","\n","    #tokenize and truncate text\n","    tokenizer.truncation_side = \"left\"\n","    tokenized_inputs = tokenizer(\n","        text,\n","        return_tensors=\"np\",\n","        truncation=True,\n","        max_length=2048\n","    )\n","\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.289096Z","iopub.status.idle":"2023-12-04T21:44:53.290484Z","shell.execute_reply":"2023-12-04T21:44:53.290168Z","shell.execute_reply.started":"2023-12-04T21:44:53.290129Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map:   0%|          | 0/17577 [00:00<?, ? examples/s]"]},{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 17577/17577 [00:00<00:00, 31239.86 examples/s]\n","Map: 100%|██████████| 7534/7534 [00:00<00:00, 30720.00 examples/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text', 'input_ids', 'attention_mask'],\n","        num_rows: 17577\n","    })\n","    test: Dataset({\n","        features: ['label', 'text', 'input_ids', 'attention_mask'],\n","        num_rows: 7534\n","    })\n","})"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["# tokenize training and validation datasets\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_dataset"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.292134Z","iopub.status.idle":"2023-12-04T21:44:53.292795Z","shell.execute_reply":"2023-12-04T21:44:53.292497Z","shell.execute_reply.started":"2023-12-04T21:44:53.292469Z"},"trusted":true},"outputs":[],"source":["# create data collator (similar to a pytorch dataloader)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.294043Z","iopub.status.idle":"2023-12-04T21:44:53.294731Z","shell.execute_reply":"2023-12-04T21:44:53.294429Z","shell.execute_reply.started":"2023-12-04T21:44:53.294397Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading builder script: 100%|██████████| 7.55k/7.55k [00:00<00:00, 5.14MB/s]\n","Downloading builder script: 100%|██████████| 7.36k/7.36k [00:00<00:00, 5.33MB/s]\n","Downloading builder script: 100%|██████████| 6.77k/6.77k [00:00<00:00, 5.10MB/s]\n"]}],"source":["# import accuracy evaluation metric\n","accuracy = evaluate.load(\"accuracy\")\n","precision = evaluate.load(\"precision\")\n","recall = evaluate.load(\"recall\")\n","f1 = evaluate.load(\"f1\")"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.295975Z","iopub.status.idle":"2023-12-04T21:44:53.296491Z","shell.execute_reply":"2023-12-04T21:44:53.296228Z","shell.execute_reply.started":"2023-12-04T21:44:53.296208Z"},"trusted":true},"outputs":[],"source":["# define an evaluation function to pass into trainer later\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels), \n","            \"precision\": precision.compute(predictions=predictions, references=labels),\n","            \"recall\": recall.compute(predictions=predictions, references=labels),\n","            \"f1\": f1.compute(predictions=predictions, references=labels)}"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["\n","def evaluate_model(examples):\n","    correct = 0\n","    for sentence in examples:\n","        # tokenize text\n","        inputs = tokenizer.encode(sentence[\"text\"], return_tensors=\"pt\").to(model.device)\n","        # compute logits\n","        logits = model(inputs).logits\n","        # convert logits to label\n","        predictions = torch.argmax(logits)\n","        \n","        if predictions.item() == sentence[\"label\"]:\n","            correct += 1\n","\n","        print(sentence[\"text\"])\n","        print(\"Predicted:\", id2label[predictions.item()] + \", Actual:\", id2label[sentence[\"label\"]])\n","    print(\"Accuracy:\", correct/len(examples))"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.299981Z","iopub.status.idle":"2023-12-04T21:44:53.300596Z","shell.execute_reply":"2023-12-04T21:44:53.300319Z","shell.execute_reply.started":"2023-12-04T21:44:53.300287Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Untrained model predictions:\n","----------------------------\n","The employee leads them to their table\n","Predicted: Irrelevant, Actual: Relevant\n","The steam will allow the pores to open zero blackheads goal  \n","Predicted: Irrelevant, Actual: Relevant\n","The still warm conched chocolate is placed in a tempering machine so that it can be slowly and steadily cooled \n","Predicted: Irrelevant, Actual: Relevant\n","The largest panel left open is the outside back\n","Predicted: Irrelevant, Actual: Irrelevant\n","The user recovers his password\n","Predicted: Irrelevant, Actual: Relevant\n","The bass strings are also wrapped with copper windings in a process called loading the strings\n","Predicted: Relevant, Actual: Irrelevant\n","The employees and students take the shelving toll to fill the shelves\n","Predicted: Irrelevant, Actual: Relevant\n","After the particular thread for ribbon has been spun dyed and treated it is rolled on bobbins\n","Predicted: Irrelevant, Actual: Relevant\n","The packaging team arrives in the department\n","Predicted: Irrelevant, Actual: Relevant\n","Plate guides are inserted at intervals of five to six bags\n","Predicted: Relevant, Actual: Relevant\n","Accuracy: 0.2\n"]}],"source":["# define list of examples\n","examples = dataset[\"test\"].shuffle().select(range(10))\n","\n","print(\"Untrained model predictions:\")\n","print(\"----------------------------\")\n","evaluate_model(examples)"]},{"cell_type":"markdown","metadata":{},"source":["# Train model"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.302464Z","iopub.status.idle":"2023-12-04T21:44:53.303107Z","shell.execute_reply":"2023-12-04T21:44:53.302922Z","shell.execute_reply.started":"2023-12-04T21:44:53.302899Z"},"trusted":true},"outputs":[],"source":["peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n","                        r=4,\n","                        lora_alpha=32,\n","                        lora_dropout=0.01,\n","                        target_modules = ['q_lin', 'v_lin'])"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.304313Z","iopub.status.idle":"2023-12-04T21:44:53.305013Z","shell.execute_reply":"2023-12-04T21:44:53.304814Z","shell.execute_reply.started":"2023-12-04T21:44:53.304784Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 665,858 || all params: 67,620,868 || trainable%: 0.9846930684178736\n"]}],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.306177Z","iopub.status.idle":"2023-12-04T21:44:53.306850Z","shell.execute_reply":"2023-12-04T21:44:53.306661Z","shell.execute_reply.started":"2023-12-04T21:44:53.306635Z"},"trusted":true},"outputs":[],"source":["# hyperparameters\n","lr = 1e-3\n","batch_size = 16\n","num_epochs = 10\n","weight_decay=0.01"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.308042Z","iopub.status.idle":"2023-12-04T21:44:53.308707Z","shell.execute_reply":"2023-12-04T21:44:53.308502Z","shell.execute_reply.started":"2023-12-04T21:44:53.308474Z"},"trusted":true},"outputs":[],"source":["# define training arguments\n","training_args = TrainingArguments(\n","    output_dir= model_name + \"-lora-text-classification\",\n","    learning_rate=lr,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=num_epochs,\n","    weight_decay=weight_decay,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.310224Z","iopub.status.idle":"2023-12-04T21:44:53.311111Z","shell.execute_reply":"2023-12-04T21:44:53.310821Z","shell.execute_reply.started":"2023-12-04T21:44:53.310792Z"},"trusted":true},"outputs":[],"source":["# creater trainer object\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.status.busy":"2023-12-04T21:44:53.312573Z","iopub.status.idle":"2023-12-04T21:44:53.313413Z","shell.execute_reply":"2023-12-04T21:44:53.313108Z","shell.execute_reply.started":"2023-12-04T21:44:53.313081Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10990' max='10990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10990/10990 15:42, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.292800</td>\n","      <td>0.269754</td>\n","      <td>{'accuracy': 0.8879745155295992}</td>\n","      <td>{'precision': 0.9380849532037437}</td>\n","      <td>{'recall': 0.9124649859943977}</td>\n","      <td>{'f1': 0.9250976215832446}</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.278400</td>\n","      <td>0.279250</td>\n","      <td>{'accuracy': 0.8926201221130874}</td>\n","      <td>{'precision': 0.9217271632547738}</td>\n","      <td>{'recall': 0.9380252100840336}</td>\n","      <td>{'f1': 0.9298047722342734}</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.246300</td>\n","      <td>0.294752</td>\n","      <td>{'accuracy': 0.8910273427130343}</td>\n","      <td>{'precision': 0.9241977450130096}</td>\n","      <td>{'recall': 0.9327731092436975}</td>\n","      <td>{'f1': 0.9284656269059858}</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.240800</td>\n","      <td>0.266015</td>\n","      <td>{'accuracy': 0.8863817361295461}</td>\n","      <td>{'precision': 0.9360632183908046}</td>\n","      <td>{'recall': 0.9124649859943977}</td>\n","      <td>{'f1': 0.9241134751773049}</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.222000</td>\n","      <td>0.289466</td>\n","      <td>{'accuracy': 0.8875763206795859}</td>\n","      <td>{'precision': 0.9330603525013352}</td>\n","      <td>{'recall': 0.9175420168067226}</td>\n","      <td>{'f1': 0.9252361196928237}</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.203400</td>\n","      <td>0.292783</td>\n","      <td>{'accuracy': 0.895009291213167}</td>\n","      <td>{'precision': 0.9225485145114203}</td>\n","      <td>{'recall': 0.9404761904761905}</td>\n","      <td>{'f1': 0.9314260944950152}</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.178300</td>\n","      <td>0.340588</td>\n","      <td>{'accuracy': 0.8930183169631006}</td>\n","      <td>{'precision': 0.9139385757678029}</td>\n","      <td>{'recall': 0.9481792717086834}</td>\n","      <td>{'f1': 0.9307441141089534}</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.163800</td>\n","      <td>0.361224</td>\n","      <td>{'accuracy': 0.8944783647464826}</td>\n","      <td>{'precision': 0.9173315226616873}</td>\n","      <td>{'recall': 0.946078431372549}</td>\n","      <td>{'f1': 0.9314832370938549}</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.138900</td>\n","      <td>0.420212</td>\n","      <td>{'accuracy': 0.8916910007963897}</td>\n","      <td>{'precision': 0.920041180507893}</td>\n","      <td>{'recall': 0.9387254901960784}</td>\n","      <td>{'f1': 0.9292894280762565}</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.122800</td>\n","      <td>0.493573</td>\n","      <td>{'accuracy': 0.8918237324130608}</td>\n","      <td>{'precision': 0.9216462889615981}</td>\n","      <td>{'recall': 0.9369747899159664}</td>\n","      <td>{'f1': 0.9292473304974391}</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=10990, training_loss=0.20777345610489295, metrics={'train_runtime': 942.9347, 'train_samples_per_second': 186.407, 'train_steps_per_second': 11.655, 'total_flos': 1806901996184688.0, 'train_loss': 0.20777345610489295, 'epoch': 10.0})"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["# # train model\n","trainer.train()"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The employee leads them to their table\n","Predicted: Relevant, Actual: Relevant\n","The steam will allow the pores to open zero blackheads goal  \n","Predicted: Irrelevant, Actual: Relevant\n","The still warm conched chocolate is placed in a tempering machine so that it can be slowly and steadily cooled \n","Predicted: Relevant, Actual: Relevant\n","The largest panel left open is the outside back\n","Predicted: Irrelevant, Actual: Irrelevant\n","The user recovers his password\n","Predicted: Relevant, Actual: Relevant\n","The bass strings are also wrapped with copper windings in a process called loading the strings\n","Predicted: Relevant, Actual: Irrelevant\n","The employees and students take the shelving toll to fill the shelves\n","Predicted: Relevant, Actual: Relevant\n","After the particular thread for ribbon has been spun dyed and treated it is rolled on bobbins\n","Predicted: Relevant, Actual: Relevant\n","The packaging team arrives in the department\n","Predicted: Relevant, Actual: Relevant\n","Plate guides are inserted at intervals of five to six bags\n","Predicted: Relevant, Actual: Relevant\n","Accuracy: 0.8\n"]}],"source":["evaluate_model(examples)"]},{"cell_type":"markdown","metadata":{},"source":["# Save fine-tuned model"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"data":{"text/plain":["('distilbert-base-uncased-lora-text-classification/tokenizer_config.json',\n"," 'distilbert-base-uncased-lora-text-classification/special_tokens_map.json',\n"," 'distilbert-base-uncased-lora-text-classification/vocab.txt',\n"," 'distilbert-base-uncased-lora-text-classification/added_tokens.json',\n"," 'distilbert-base-uncased-lora-text-classification/tokenizer.json')"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["peft_model_id = \"distilbert-base-uncased-lora-text-classification\"\n","trainer.save_model(peft_model_id)\n","tokenizer.save_pretrained(peft_model_id)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["config = PeftConfig.from_pretrained(peft_model_id)\n","\n","test_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, label2id=label2id)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","model_inf = PeftModel.from_pretrained(test_model, peft_model_id)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The employee leads them to their table\n","Predicted: Relevant, Actual: Relevant\n","The steam will allow the pores to open zero blackheads goal  \n","Predicted: Irrelevant, Actual: Relevant\n","The still warm conched chocolate is placed in a tempering machine so that it can be slowly and steadily cooled \n","Predicted: Relevant, Actual: Relevant\n","The largest panel left open is the outside back\n","Predicted: Irrelevant, Actual: Irrelevant\n","The user recovers his password\n","Predicted: Relevant, Actual: Relevant\n","The bass strings are also wrapped with copper windings in a process called loading the strings\n","Predicted: Relevant, Actual: Irrelevant\n","The employees and students take the shelving toll to fill the shelves\n","Predicted: Relevant, Actual: Relevant\n","After the particular thread for ribbon has been spun dyed and treated it is rolled on bobbins\n","Predicted: Relevant, Actual: Relevant\n","The packaging team arrives in the department\n","Predicted: Relevant, Actual: Relevant\n","Plate guides are inserted at intervals of five to six bags\n","Predicted: Relevant, Actual: Relevant\n","Accuracy: 0.8\n"]}],"source":["evaluate_model(examples)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30588,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
