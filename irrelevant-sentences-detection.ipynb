{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7129783,"sourceType":"datasetVersion","datasetId":4113409}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft\n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T13:35:56.561234Z","iopub.execute_input":"2023-12-05T13:35:56.562356Z","iopub.status.idle":"2023-12-05T13:36:20.050038Z","shell.execute_reply.started":"2023-12-05T13:35:56.562308Z","shell.execute_reply":"2023-12-05T13:36:20.049001Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.6.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.35.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.17.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.14.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.10.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport transformers\nimport torch\n\nfrom datasets import load_dataset, DatasetDict, Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig, \n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer)\n\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport evaluate\nimport torch\nimport numpy as np\nimport pandas as pd\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:20.052353Z","iopub.execute_input":"2023-12-05T13:36:20.052736Z","iopub.status.idle":"2023-12-05T13:36:20.059477Z","shell.execute_reply.started":"2023-12-05T13:36:20.052703Z","shell.execute_reply":"2023-12-05T13:36:20.058395Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# model_name = \"tiiuae/falcon-7b\"\n# model_name = \"tiiuae/falcon-rw-1b\"\nmodel_name = \"distilbert-base-uncased\"\nmistral = \"mistralai/Mistral-7B-v0.1\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T13:36:20.060780Z","iopub.execute_input":"2023-12-05T13:36:20.061128Z","iopub.status.idle":"2023-12-05T13:36:20.204192Z","shell.execute_reply.started":"2023-12-05T13:36:20.061091Z","shell.execute_reply":"2023-12-05T13:36:20.203238Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# define label maps\nid2label = {0: \"Irrelevant\", 1: \"Relevant\"}\nlabel2id = {\"Irrelevant\":0, \"Relevant\":1}\n\n# generate classification model from model_checkpoint\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name, num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:20.206929Z","iopub.execute_input":"2023-12-05T13:36:20.207303Z","iopub.status.idle":"2023-12-05T13:36:20.969364Z","shell.execute_reply.started":"2023-12-05T13:36:20.207269Z","shell.execute_reply":"2023-12-05T13:36:20.968392Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize input text\ninput_text = \"Hello\"\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Inference\noutputs = model(**inputs)\n\n# Post-processing\nlogits = outputs.logits\npredicted_class = torch.argmax(logits, dim=1).item()\nprint(\"Predicted Class:\", predicted_class)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:20.970684Z","iopub.execute_input":"2023-12-05T13:36:20.971001Z","iopub.status.idle":"2023-12-05T13:36:21.004953Z","shell.execute_reply.started":"2023-12-05T13:36:20.970973Z","shell.execute_reply":"2023-12-05T13:36:21.003930Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Predicted Class: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Low Rank Adaptation Fine Tuning","metadata":{}},{"cell_type":"markdown","source":"## Dataset Gathering","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/irrelevance-sentences-dataset/WaTA_dataset.csv', encoding = \"ISO-8859-1\")\n\ntest_set = 0.3\n\nx_train, y_train, x_test, y_test = [], [], [] ,[]\nfor index, row in df.iterrows():\n    if random.random() < test_set:\n        # TEST SET\n        x_test.append(row['Sentence'])\n        y_test.append(label2id[row['Class']])\n    else:\n        # TRAINING SET\n        x_train.append(row['Sentence'])\n        y_train.append(label2id[row['Class']])\n        \ndataset = DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n                        'test':Dataset.from_dict({'label':y_test,'text':x_test})})","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:21.006208Z","iopub.execute_input":"2023-12-05T13:36:21.006478Z","iopub.status.idle":"2023-12-05T13:36:22.550165Z","shell.execute_reply.started":"2023-12-05T13:36:21.006454Z","shell.execute_reply":"2023-12-05T13:36:22.549094Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:22.551510Z","iopub.execute_input":"2023-12-05T13:36:22.551835Z","iopub.status.idle":"2023-12-05T13:36:22.558499Z","shell.execute_reply.started":"2023-12-05T13:36:22.551807Z","shell.execute_reply":"2023-12-05T13:36:22.557453Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'text'],\n        num_rows: 17586\n    })\n    test: Dataset({\n        features: ['label', 'text'],\n        num_rows: 7525\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"# add pad token if none exists\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:22.559785Z","iopub.execute_input":"2023-12-05T13:36:22.560576Z","iopub.status.idle":"2023-12-05T13:36:22.566403Z","shell.execute_reply.started":"2023-12-05T13:36:22.560543Z","shell.execute_reply":"2023-12-05T13:36:22.565385Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# create tokenize function\ndef tokenize_function(examples):\n    # extract text\n    text = examples[\"text\"]\n\n    #tokenize and truncate text\n    tokenizer.truncation_side = \"left\"\n    tokenized_inputs = tokenizer(\n        text,\n        return_tensors=\"np\",\n        truncation=True,\n        max_length=512\n    )\n\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:22.567578Z","iopub.execute_input":"2023-12-05T13:36:22.567858Z","iopub.status.idle":"2023-12-05T13:36:22.578619Z","shell.execute_reply.started":"2023-12-05T13:36:22.567835Z","shell.execute_reply":"2023-12-05T13:36:22.577811Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# tokenize training and validation datasets\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:22.582160Z","iopub.execute_input":"2023-12-05T13:36:22.582455Z","iopub.status.idle":"2023-12-05T13:36:23.820637Z","shell.execute_reply.started":"2023-12-05T13:36:22.582424Z","shell.execute_reply":"2023-12-05T13:36:23.819751Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"835263446a104fc98ef5153992e0a553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c535cc57cd54f749b874f481a49bf1c"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'text', 'input_ids', 'attention_mask'],\n        num_rows: 17586\n    })\n    test: Dataset({\n        features: ['label', 'text', 'input_ids', 'attention_mask'],\n        num_rows: 7525\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# create data collator (similar to a pytorch dataloader)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:23.821831Z","iopub.execute_input":"2023-12-05T13:36:23.822095Z","iopub.status.idle":"2023-12-05T13:36:23.826488Z","shell.execute_reply.started":"2023-12-05T13:36:23.822072Z","shell.execute_reply":"2023-12-05T13:36:23.825436Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# import accuracy evaluation metric\naccuracy = evaluate.load(\"accuracy\")\nrecall = evaluate.load(\"recall\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:23.827844Z","iopub.execute_input":"2023-12-05T13:36:23.828153Z","iopub.status.idle":"2023-12-05T13:36:24.675086Z","shell.execute_reply.started":"2023-12-05T13:36:23.828125Z","shell.execute_reply":"2023-12-05T13:36:24.674098Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# define an evaluation function to pass into trainer later\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=1)\n\n    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:24.676292Z","iopub.execute_input":"2023-12-05T13:36:24.676604Z","iopub.status.idle":"2023-12-05T13:36:24.681975Z","shell.execute_reply.started":"2023-12-05T13:36:24.676577Z","shell.execute_reply":"2023-12-05T13:36:24.680896Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# define list of examples\ntext_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n\nprint(\"Untrained model predictions:\")\nprint(\"----------------------------\")\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n    # compute logits\n    logits = model(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n\n    print(text + \" - \" + id2label[predictions.tolist()])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:24.683337Z","iopub.execute_input":"2023-12-05T13:36:24.683695Z","iopub.status.idle":"2023-12-05T13:36:24.849753Z","shell.execute_reply.started":"2023-12-05T13:36:24.683660Z","shell.execute_reply":"2023-12-05T13:36:24.848738Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Untrained model predictions:\n----------------------------\nIt was good. - Irrelevant\nNot a fan, don't recommed. - Irrelevant\nBetter than the first one. - Irrelevant\nThis is not worth watching even once. - Irrelevant\nThis one is a pass. - Irrelevant\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n                        r=4,\n                        lora_alpha=32,\n                        lora_dropout=0.01,\n                        target_modules = ['q_lin'])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:24.851110Z","iopub.execute_input":"2023-12-05T13:36:24.851449Z","iopub.status.idle":"2023-12-05T13:36:24.856452Z","shell.execute_reply.started":"2023-12-05T13:36:24.851420Z","shell.execute_reply":"2023-12-05T13:36:24.855463Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:36:24.857672Z","iopub.execute_input":"2023-12-05T13:36:24.857997Z","iopub.status.idle":"2023-12-05T13:36:24.878279Z","shell.execute_reply.started":"2023-12-05T13:36:24.857972Z","shell.execute_reply":"2023-12-05T13:36:24.877374Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9306847223789819\n","output_type":"stream"}]},{"cell_type":"code","source":"# hyperparameters\nlr = 1e-3\nbatch_size = 4\nnum_epochs = 40\nweight_decay=0.01","metadata":{"execution":{"iopub.status.busy":"2023-12-05T16:09:02.618172Z","iopub.execute_input":"2023-12-05T16:09:02.618592Z","iopub.status.idle":"2023-12-05T16:09:02.625823Z","shell.execute_reply.started":"2023-12-05T16:09:02.618560Z","shell.execute_reply":"2023-12-05T16:09:02.624608Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# define training arguments\ntraining_args = TrainingArguments(\n    output_dir= model_name + \"-lora-text-classification\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=weight_decay,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T16:09:04.907646Z","iopub.execute_input":"2023-12-05T16:09:04.908508Z","iopub.status.idle":"2023-12-05T16:09:04.918460Z","shell.execute_reply.started":"2023-12-05T16:09:04.908474Z","shell.execute_reply":"2023-12-05T16:09:04.917205Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# creater trainer object\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T16:09:18.584176Z","iopub.execute_input":"2023-12-05T16:09:18.584601Z","iopub.status.idle":"2023-12-05T16:09:18.672361Z","shell.execute_reply.started":"2023-12-05T16:09:18.584567Z","shell.execute_reply":"2023-12-05T16:09:18.671125Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# # train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T16:09:21.635046Z","iopub.execute_input":"2023-12-05T16:09:21.635417Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='87360' max='175880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 87360/175880 38:02 < 38:33, 38.27 it/s, Epoch 19.87/40]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.543200</td>\n      <td>0.602479</td>\n      <td>{'accuracy': 0.8299003322259136}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.597900</td>\n      <td>0.607633</td>\n      <td>{'accuracy': 0.8296345514950166}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.567800</td>\n      <td>0.511948</td>\n      <td>{'accuracy': 0.8229900332225913}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.601900</td>\n      <td>0.673860</td>\n      <td>{'accuracy': 0.8176744186046512}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.637800</td>\n      <td>0.559299</td>\n      <td>{'accuracy': 0.8285714285714286}</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.591000</td>\n      <td>0.667544</td>\n      <td>{'accuracy': 0.815813953488372}</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.573800</td>\n      <td>1.021640</td>\n      <td>{'accuracy': 0.761860465116279}</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.587000</td>\n      <td>0.541113</td>\n      <td>{'accuracy': 0.761594684385382}</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.614300</td>\n      <td>0.627786</td>\n      <td>{'accuracy': 0.7788704318936877}</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.577500</td>\n      <td>0.517419</td>\n      <td>{'accuracy': 0.7867109634551495}</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.547400</td>\n      <td>0.504352</td>\n      <td>{'accuracy': 0.8031893687707641}</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.601300</td>\n      <td>0.654614</td>\n      <td>{'accuracy': 0.800265780730897}</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.543500</td>\n      <td>0.630804</td>\n      <td>{'accuracy': 0.7735548172757475}</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.553500</td>\n      <td>0.540665</td>\n      <td>{'accuracy': 0.7875083056478406}</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.549900</td>\n      <td>0.500394</td>\n      <td>{'accuracy': 0.7976079734219269}</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.561700</td>\n      <td>0.499455</td>\n      <td>{'accuracy': 0.8059800664451827}</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.507500</td>\n      <td>0.570689</td>\n      <td>{'accuracy': 0.8066445182724252}</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.588800</td>\n      <td>0.558986</td>\n      <td>{'accuracy': 0.8051827242524917}</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.518500</td>\n      <td>0.483067</td>\n      <td>{'accuracy': 0.8118272425249169}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'accuracy': 0.8299003322259136}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8296345514950166}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8229900332225913}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8176744186046512}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8285714285714286}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.815813953488372}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.761860465116279}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.761594684385382}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.7788704318936877}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.7867109634551495}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8031893687707641}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.800265780730897}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.7735548172757475}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.7875083056478406}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.7976079734219269}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8059800664451827}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8066445182724252}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8051827242524917}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'accuracy': 0.8118272425249169}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"}]},{"cell_type":"code","source":"# define list of examples\ntext_list = [\"The party sends a warrant possession request asking a warrant to be released\", #R\n             \"If the request is rejected the process will end\", #R\n             \"For instance a sales person on a trip rents a car\", #I\n             \"Since the company has expense rules there are circumstances where the supervisor can accept or reject the report upon first inspection\", #I\n             \"This notice is done by the family doctor of somebody who is in need of mental treatment\", #I\n             \"Unfortunately it is not coupled correctly to our Enterprise Resource Planning system ERP so the data must be transferred manually\", #I\n             \"The customer enters the withdrawal amount\", #R\n             \"Once that information is present it has to be entered into our production planning system PPS\", #R\n             \"Besides it creates a list of parts to be procured\", #R\n             \"A teenager who obtains 44 out of 50 is good for example\"] #I\n\nprint(\"Trained model predictions:\")\nprint(\"----------------------------\")\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n    # compute logits\n    logits = model.cpu()(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n\n    print(text + \" - \" + id2label[predictions.tolist()])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T16:08:38.248008Z","iopub.execute_input":"2023-12-05T16:08:38.248807Z","iopub.status.idle":"2023-12-05T16:08:38.791360Z","shell.execute_reply.started":"2023-12-05T16:08:38.248771Z","shell.execute_reply":"2023-12-05T16:08:38.790030Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Trained model predictions:\n----------------------------\nThe party sends a warrant possession request asking a warrant to be released - Relevant\nIf the request is rejected the process will end - Relevant\nFor instance a sales person on a trip rents a car - Irrelevant\nSince the company has expense rules there are circumstances where the supervisor can accept or reject the report upon first inspection - Relevant\nThis notice is done by the family doctor of somebody who is in need of mental treatment - Relevant\nUnfortunately it is not coupled correctly to our Enterprise Resource Planning system ERP so the data must be transferred manually - Irrelevant\nThe customer enters the withdrawal amount - Relevant\nOnce that information is present it has to be entered into our production planning system PPS - Relevant\nBesides it creates a list of parts to be procured - Irrelevant\nA teenager who obtains 44 out of 50 is good for example - Relevant\n","output_type":"stream"}]}]}