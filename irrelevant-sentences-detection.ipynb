{"cells":[{"cell_type":"code","execution_count":21,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-05T13:35:56.562356Z","iopub.status.busy":"2023-12-05T13:35:56.561234Z","iopub.status.idle":"2023-12-05T13:36:20.050038Z","shell.execute_reply":"2023-12-05T13:36:20.049001Z","shell.execute_reply.started":"2023-12-05T13:35:56.562308Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.6.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.35.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.1)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.17.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.14.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"]}],"source":["!pip install peft\n","!pip install evaluate"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:20.052736Z","iopub.status.busy":"2023-12-05T13:36:20.052353Z","iopub.status.idle":"2023-12-05T13:36:20.059477Z","shell.execute_reply":"2023-12-05T13:36:20.058395Z","shell.execute_reply.started":"2023-12-05T13:36:20.052703Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\adrie\\miniconda3\\envs\\hf\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import transformers\n","import torch\n","\n","from datasets import load_dataset, DatasetDict, Dataset\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig, \n","    AutoModelForSequenceClassification,\n","    DataCollatorWithPadding,\n","    TrainingArguments,\n","    Trainer)\n","\n","from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n","import evaluate\n","import torch\n","import numpy as np\n","import pandas as pd\n","import random"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-05T13:36:20.061128Z","iopub.status.busy":"2023-12-05T13:36:20.060780Z","iopub.status.idle":"2023-12-05T13:36:20.204192Z","shell.execute_reply":"2023-12-05T13:36:20.203238Z","shell.execute_reply.started":"2023-12-05T13:36:20.061091Z"},"trusted":true},"outputs":[],"source":["# model_name = \"tiiuae/falcon-7b\"\n","# model_name = \"tiiuae/falcon-rw-1b\"\n","model_name = \"distilbert-base-uncased\"\n","mistral = \"mistralai/Mistral-7B-v0.1\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:20.207303Z","iopub.status.busy":"2023-12-05T13:36:20.206929Z","iopub.status.idle":"2023-12-05T13:36:20.969364Z","shell.execute_reply":"2023-12-05T13:36:20.968392Z","shell.execute_reply.started":"2023-12-05T13:36:20.207269Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# define label maps\n","id2label = {0: \"Irrelevant\", 1: \"Relevant\"}\n","label2id = {\"Irrelevant\":0, \"Relevant\":1}\n","\n","# generate classification model from model_checkpoint\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name, num_labels=2, id2label=id2label, label2id=label2id)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:20.971001Z","iopub.status.busy":"2023-12-05T13:36:20.970684Z","iopub.status.idle":"2023-12-05T13:36:21.004953Z","shell.execute_reply":"2023-12-05T13:36:21.003930Z","shell.execute_reply.started":"2023-12-05T13:36:20.970973Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Class: 0\n"]}],"source":["# Tokenize input text\n","input_text = \"Hello\"\n","inputs = tokenizer(input_text, return_tensors=\"pt\")\n","\n","# Inference\n","outputs = model(**inputs)\n","\n","# Post-processing\n","logits = outputs.logits\n","predicted_class = torch.argmax(logits, dim=1).item()\n","print(\"Predicted Class:\", predicted_class)"]},{"cell_type":"markdown","metadata":{},"source":["# Low Rank Adaptation Fine Tuning"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Gathering"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:21.006478Z","iopub.status.busy":"2023-12-05T13:36:21.006208Z","iopub.status.idle":"2023-12-05T13:36:22.550165Z","shell.execute_reply":"2023-12-05T13:36:22.549094Z","shell.execute_reply.started":"2023-12-05T13:36:21.006454Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('WaTA_dataset.csv', encoding = \"ISO-8859-1\")\n","\n","test_set = 0.3\n","\n","x_train, y_train, x_test, y_test = [], [], [] ,[]\n","for index, row in df.iterrows():\n","    if random.random() < test_set:\n","        # TEST SET\n","        x_test.append(row['Sentence'])\n","        y_test.append(label2id[row['Class']])\n","    else:\n","        # TRAINING SET\n","        x_train.append(row['Sentence'])\n","        y_train.append(label2id[row['Class']])\n","        \n","dataset = DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n","                        'test':Dataset.from_dict({'label':y_test,'text':x_test})})"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:22.551835Z","iopub.status.busy":"2023-12-05T13:36:22.551510Z","iopub.status.idle":"2023-12-05T13:36:22.558499Z","shell.execute_reply":"2023-12-05T13:36:22.557453Z","shell.execute_reply.started":"2023-12-05T13:36:22.551807Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text'],\n","        num_rows: 17554\n","    })\n","    test: Dataset({\n","        features: ['label', 'text'],\n","        num_rows: 7557\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:22.560576Z","iopub.status.busy":"2023-12-05T13:36:22.559785Z","iopub.status.idle":"2023-12-05T13:36:22.566403Z","shell.execute_reply":"2023-12-05T13:36:22.565385Z","shell.execute_reply.started":"2023-12-05T13:36:22.560543Z"},"trusted":true},"outputs":[],"source":["# add pad token if none exists\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:22.567858Z","iopub.status.busy":"2023-12-05T13:36:22.567578Z","iopub.status.idle":"2023-12-05T13:36:22.578619Z","shell.execute_reply":"2023-12-05T13:36:22.577811Z","shell.execute_reply.started":"2023-12-05T13:36:22.567835Z"},"trusted":true},"outputs":[],"source":["# create tokenize function\n","def tokenize_function(examples):\n","    # extract text\n","    text = examples[\"text\"]\n","\n","    #tokenize and truncate text\n","    tokenizer.truncation_side = \"left\"\n","    tokenized_inputs = tokenizer(\n","        text,\n","        return_tensors=\"np\",\n","        truncation=True,\n","        max_length=512\n","    )\n","\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:22.582455Z","iopub.status.busy":"2023-12-05T13:36:22.582160Z","iopub.status.idle":"2023-12-05T13:36:23.820637Z","shell.execute_reply":"2023-12-05T13:36:23.819751Z","shell.execute_reply.started":"2023-12-05T13:36:22.582424Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map:   0%|          | 0/17554 [00:00<?, ? examples/s]"]},{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 17554/17554 [00:02<00:00, 6785.15 examples/s]\n","Map: 100%|██████████| 7557/7557 [00:01<00:00, 6619.08 examples/s]\n"]},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text', 'input_ids', 'attention_mask'],\n","        num_rows: 17554\n","    })\n","    test: Dataset({\n","        features: ['label', 'text', 'input_ids', 'attention_mask'],\n","        num_rows: 7557\n","    })\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# tokenize training and validation datasets\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:23.822095Z","iopub.status.busy":"2023-12-05T13:36:23.821831Z","iopub.status.idle":"2023-12-05T13:36:23.826488Z","shell.execute_reply":"2023-12-05T13:36:23.825436Z","shell.execute_reply.started":"2023-12-05T13:36:23.822072Z"},"trusted":true},"outputs":[],"source":["# create data collator (similar to a pytorch dataloader)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:23.828153Z","iopub.status.busy":"2023-12-05T13:36:23.827844Z","iopub.status.idle":"2023-12-05T13:36:24.675086Z","shell.execute_reply":"2023-12-05T13:36:24.674098Z","shell.execute_reply.started":"2023-12-05T13:36:23.828125Z"},"trusted":true},"outputs":[{"ename":"ImportError","evalue":"To be able to use evaluate-metric/accuracy, you need to install the following dependencies['scikit-learn'] using 'pip install sklearn' for instance'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32mc:\\Users\\adrie\\Git\\few-shot-learning-LLM\\irrelevant-sentences-detection.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adrie/Git/few-shot-learning-LLM/irrelevant-sentences-detection.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import accuracy evaluation metric\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adrie/Git/few-shot-learning-LLM/irrelevant-sentences-detection.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adrie/Git/few-shot-learning-LLM/irrelevant-sentences-detection.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m recall \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\adrie\\miniconda3\\envs\\hf\\Lib\\site-packages\\evaluate\\loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[39m=\u001b[39m DownloadMode(download_mode \u001b[39mor\u001b[39;00m DownloadMode\u001b[39m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[1;32m--> 748\u001b[0m evaluation_module \u001b[39m=\u001b[39m evaluation_module_factory(\n\u001b[0;32m    749\u001b[0m     path, module_type\u001b[39m=\u001b[39;49mmodule_type, revision\u001b[39m=\u001b[39;49mrevision, download_config\u001b[39m=\u001b[39;49mdownload_config, download_mode\u001b[39m=\u001b[39;49mdownload_mode\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    751\u001b[0m evaluation_cls \u001b[39m=\u001b[39m import_main_class(evaluation_module\u001b[39m.\u001b[39mmodule_path)\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[39m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[39m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[39m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n","File \u001b[1;32mc:\\Users\\adrie\\miniconda3\\envs\\hf\\Lib\\site-packages\\evaluate\\loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m                 \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    679\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, (\u001b[39mConnectionError\u001b[39;00m, \u001b[39mFileNotFoundError\u001b[39;00m)):\n\u001b[1;32m--> 680\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    682\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a module script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    683\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist on the Hugging Face Hub either.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    684\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\adrie\\miniconda3\\envs\\hf\\Lib\\site-packages\\evaluate\\loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mfor\u001b[39;00m current_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcomparison\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmeasurement\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    632\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    633\u001b[0m         \u001b[39mreturn\u001b[39;00m HubEvaluationModuleFactory(\n\u001b[0;32m    634\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mevaluate-\u001b[39;49m\u001b[39m{\u001b[39;49;00mcurrent_type\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    635\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    636\u001b[0m             download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m    637\u001b[0m             download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m    638\u001b[0m             dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[1;32m--> 639\u001b[0m         )\u001b[39m.\u001b[39;49mget_module()\n\u001b[0;32m    640\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m         \u001b[39mpass\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\adrie\\miniconda3\\envs\\hf\\Lib\\site-packages\\evaluate\\loading.py:489\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    488\u001b[0m imports \u001b[39m=\u001b[39m get_imports(local_path)\n\u001b[1;32m--> 489\u001b[0m local_imports \u001b[39m=\u001b[39m _download_additional_modules(\n\u001b[0;32m    490\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    491\u001b[0m     base_path\u001b[39m=\u001b[39;49mhf_hub_url(path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, revision\u001b[39m=\u001b[39;49mrevision),\n\u001b[0;32m    492\u001b[0m     imports\u001b[39m=\u001b[39;49mimports,\n\u001b[0;32m    493\u001b[0m     download_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config,\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    495\u001b[0m \u001b[39m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[0;32m    496\u001b[0m dynamic_modules_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_modules_path \u001b[39melse\u001b[39;00m init_dynamic_modules()\n","File \u001b[1;32mc:\\Users\\adrie\\miniconda3\\envs\\hf\\Lib\\site-packages\\evaluate\\loading.py:265\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[1;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[0;32m    263\u001b[0m         needs_to_be_installed\u001b[39m.\u001b[39madd((library_import_name, library_import_path))\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m needs_to_be_installed:\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    266\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTo be able to use \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m, you need to install the following dependencies\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m[lib_name\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlib_name,\u001b[39m \u001b[39mlib_path\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mneeds_to_be_installed]\u001b[39m}\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lib_path\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mlib_name,\u001b[39m \u001b[39mlib_path\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mneeds_to_be_installed])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for instance\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m     )\n\u001b[0;32m    270\u001b[0m \u001b[39mreturn\u001b[39;00m local_imports\n","\u001b[1;31mImportError\u001b[0m: To be able to use evaluate-metric/accuracy, you need to install the following dependencies['scikit-learn'] using 'pip install sklearn' for instance'"]}],"source":["# import accuracy evaluation metric\n","accuracy = evaluate.load(\"accuracy\")\n","recall = evaluate.load(\"recall\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:24.676604Z","iopub.status.busy":"2023-12-05T13:36:24.676292Z","iopub.status.idle":"2023-12-05T13:36:24.681975Z","shell.execute_reply":"2023-12-05T13:36:24.680896Z","shell.execute_reply.started":"2023-12-05T13:36:24.676577Z"},"trusted":true},"outputs":[],"source":["# define an evaluation function to pass into trainer later\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:24.683695Z","iopub.status.busy":"2023-12-05T13:36:24.683337Z","iopub.status.idle":"2023-12-05T13:36:24.849753Z","shell.execute_reply":"2023-12-05T13:36:24.848738Z","shell.execute_reply.started":"2023-12-05T13:36:24.683660Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Untrained model predictions:\n","----------------------------\n","It was good. - Irrelevant\n"]},{"name":"stdout","output_type":"stream","text":["Not a fan, don't recommed. - Irrelevant\n","Better than the first one. - Irrelevant\n","This is not worth watching even once. - Irrelevant\n","This one is a pass. - Irrelevant\n"]}],"source":["# define list of examples\n","text_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]\n","\n","print(\"Untrained model predictions:\")\n","print(\"----------------------------\")\n","for text in text_list:\n","    # tokenize text\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n","    # compute logits\n","    logits = model(inputs).logits\n","    # convert logits to label\n","    predictions = torch.argmax(logits)\n","\n","    print(text + \" - \" + id2label[predictions.tolist()])"]},{"cell_type":"markdown","metadata":{},"source":["# Train model"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:24.851449Z","iopub.status.busy":"2023-12-05T13:36:24.851110Z","iopub.status.idle":"2023-12-05T13:36:24.856452Z","shell.execute_reply":"2023-12-05T13:36:24.855463Z","shell.execute_reply.started":"2023-12-05T13:36:24.851420Z"},"trusted":true},"outputs":[],"source":["peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n","                        r=4,\n","                        lora_alpha=32,\n","                        lora_dropout=0.01,\n","                        target_modules = ['q_lin'])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T13:36:24.857997Z","iopub.status.busy":"2023-12-05T13:36:24.857672Z","iopub.status.idle":"2023-12-05T13:36:24.878279Z","shell.execute_reply":"2023-12-05T13:36:24.877374Z","shell.execute_reply.started":"2023-12-05T13:36:24.857972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9306847223789819\n"]}],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T16:09:02.618592Z","iopub.status.busy":"2023-12-05T16:09:02.618172Z","iopub.status.idle":"2023-12-05T16:09:02.625823Z","shell.execute_reply":"2023-12-05T16:09:02.624608Z","shell.execute_reply.started":"2023-12-05T16:09:02.618560Z"},"trusted":true},"outputs":[],"source":["# hyperparameters\n","lr = 1e-3\n","batch_size = 4\n","num_epochs = 40\n","weight_decay=0.01"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T16:09:04.908508Z","iopub.status.busy":"2023-12-05T16:09:04.907646Z","iopub.status.idle":"2023-12-05T16:09:04.918460Z","shell.execute_reply":"2023-12-05T16:09:04.917205Z","shell.execute_reply.started":"2023-12-05T16:09:04.908474Z"},"trusted":true},"outputs":[],"source":["# define training arguments\n","training_args = TrainingArguments(\n","    output_dir= model_name + \"-lora-text-classification\",\n","    learning_rate=lr,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=num_epochs,\n","    weight_decay=weight_decay,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T16:09:18.584601Z","iopub.status.busy":"2023-12-05T16:09:18.584176Z","iopub.status.idle":"2023-12-05T16:09:18.672361Z","shell.execute_reply":"2023-12-05T16:09:18.671125Z","shell.execute_reply.started":"2023-12-05T16:09:18.584567Z"},"trusted":true},"outputs":[],"source":["# creater trainer object\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # train model\n","trainer.train()"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T16:08:38.248807Z","iopub.status.busy":"2023-12-05T16:08:38.248008Z","iopub.status.idle":"2023-12-05T16:08:38.791360Z","shell.execute_reply":"2023-12-05T16:08:38.790030Z","shell.execute_reply.started":"2023-12-05T16:08:38.248771Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Trained model predictions:\n","----------------------------\n","The party sends a warrant possession request asking a warrant to be released - Relevant\n","If the request is rejected the process will end - Relevant\n","For instance a sales person on a trip rents a car - Irrelevant\n","Since the company has expense rules there are circumstances where the supervisor can accept or reject the report upon first inspection - Relevant\n","This notice is done by the family doctor of somebody who is in need of mental treatment - Relevant\n","Unfortunately it is not coupled correctly to our Enterprise Resource Planning system ERP so the data must be transferred manually - Irrelevant\n","The customer enters the withdrawal amount - Relevant\n","Once that information is present it has to be entered into our production planning system PPS - Relevant\n","Besides it creates a list of parts to be procured - Irrelevant\n","A teenager who obtains 44 out of 50 is good for example - Relevant\n"]}],"source":["# define list of examples\n","text_list = [\"The party sends a warrant possession request asking a warrant to be released\", #R\n","             \"If the request is rejected the process will end\", #R\n","             \"For instance a sales person on a trip rents a car\", #I\n","             \"Since the company has expense rules there are circumstances where the supervisor can accept or reject the report upon first inspection\", #I\n","             \"This notice is done by the family doctor of somebody who is in need of mental treatment\", #I\n","             \"Unfortunately it is not coupled correctly to our Enterprise Resource Planning system ERP so the data must be transferred manually\", #I\n","             \"The customer enters the withdrawal amount\", #R\n","             \"Once that information is present it has to be entered into our production planning system PPS\", #R\n","             \"Besides it creates a list of parts to be procured\", #R\n","             \"A teenager who obtains 44 out of 50 is good for example\"] #I\n","\n","print(\"Trained model predictions:\")\n","print(\"----------------------------\")\n","for text in text_list:\n","    # tokenize text\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n","    # compute logits\n","    logits = model.cpu()(inputs).logits\n","    # convert logits to label\n","    predictions = torch.argmax(logits)\n","\n","    print(text + \" - \" + id2label[predictions.tolist()])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4113409,"sourceId":7129783,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
